{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurent Neural Network for MNIST digit prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 77777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x107f38a30>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, num_hidden_layers, num_output):\n",
    "        super(RNN, self).__init__()        \n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        \n",
    "        self.rnn = nn.RNN(num_features, num_hidden, \n",
    "                          num_layers=num_hidden_layers, \n",
    "                          batch_first=True, #input/output tensors to be of shape (batch_dim, seq_dim, feature_dim)\n",
    "                          nonlinearity='relu')\n",
    "\n",
    "        self.linear_out = nn.Linear(num_hidden, num_output)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        h0 = torch.zeros(self.num_hidden_layers, inputs.size(0), self.num_hidden) # zero vector hidden state            \n",
    "        output, hidden = self.rnn(inputs, h0)        \n",
    "        # Get only hidden state of last time step --> the goal is to get the final prediction to know what digit it is\n",
    "        output = self.linear_out(output[:, -1, :]) # output.size() --> 128, 10\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 3\n",
    "\n",
    "num_features = 28\n",
    "num_hidden = 100\n",
    "num_hidden_layers = 2\n",
    "num_output = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(num_features, num_hidden, num_hidden_layers, num_output)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps to unroll\n",
    "seq_dim = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images.view(-1, seq_dim, num_features))\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(images), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(images)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "            outputs = model(images.view(-1, seq_dim, num_features))\n",
    "            test_loss += loss_function(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "        accuracy = 100 * correct / total\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}. Accuracy: {}'.format(test_loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model and evaluate on test set while it is training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.017964\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.004676\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.005399\n",
      "====> Epoch: 1 Average loss: 0.0071\n",
      "====> Test set loss: 0.0047. Accuracy: 81\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.004119\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.003240\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.003839\n",
      "====> Epoch: 2 Average loss: 0.0040\n",
      "====> Test set loss: 0.0044. Accuracy: 82\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.003488\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.003391\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.003729\n",
      "====> Epoch: 3 Average loss: 0.0037\n",
      "====> Test set loss: 0.0031. Accuracy: 88\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
