{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurent Neural Network for text generation (character level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from: https://github.com/spro/practical-pytorch/blob/master/char-rnn-generation/char-rnn-generation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 77777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the corpus - Compilation of Shakespeare texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file length is:  1115393\n",
      "\n",
      "All existing characters in the corpus: \n",
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of unique characters: 100\n"
     ]
    }
   ],
   "source": [
    "# All characters available\n",
    "all_characters = string.printable\n",
    "vocab = set(all_characters)\n",
    "n_characters = len(vocab)\n",
    "chunk_len = 200\n",
    "\n",
    "# give every character an index\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {i: word for i, word in enumerate(vocab)}\n",
    "\n",
    "file = open('./shakespeare.txt').read()\n",
    "file_len = len(file)\n",
    "print('The file length is: ', file_len)\n",
    "print()\n",
    "print(\"All existing characters in the corpus: \\n\"+str(all_characters))\n",
    "print(\"Number of unique characters: \"+str(n_characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to create chunks of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constant.\n",
      "\n",
      "KING EDWAR\n"
     ]
    }
   ],
   "source": [
    "def random_chunk(chunk_len):\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input will be all characters up to the last, and the target will be all characters from the first. <br>\n",
    "Example: <br>\n",
    "Text:\"We shall go!\" --> Input:\"We shall go\" --> Target: \"e shall go!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First \n",
      "x sample size =  5 ['F', 'i', 'r', 's', 't']\n",
      "y sample size =  5 ['i', 'r', 's', 't', ' ']\n"
     ]
    }
   ],
   "source": [
    "def textToWin(text, seq_len, step_size):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for i in range(0, len(text) - seq_len, step_size):\n",
    "        window = text[i:seq_len+i]\n",
    "        inputs.append(window)\n",
    "    outputs = [i for i in text[seq_len::step_size]]\n",
    "    return inputs, outputs\n",
    "\n",
    "_s= file[:6]\n",
    "print(a)\n",
    "inptest, outtest = textToWin(_s, 1, 1)\n",
    "print(\"x sample size = \", len(inptest), inptest)\n",
    "print(\"y sample size = \", len(outtest), outtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 46],\n",
      "        [ 67],\n",
      "        [ 81],\n",
      "        [ 82],\n",
      "        [ 11]]) tensor([ 67,  81,  82,  11,  87])\n"
     ]
    }
   ],
   "source": [
    "def textToTensor(text, seq_len, step_size):\n",
    "    inputs, outputs = textToWin(text, seq_len, step_size)\n",
    "    X = torch.zeros(len(inputs), seq_len).long()\n",
    "    y = torch.zeros(len(inputs)).long()\n",
    "    for i, seq in enumerate(inputs):\n",
    "        for t, char in enumerate(seq):\n",
    "            X[i, t] = word_to_ix[seq[t]]\n",
    "        y[i] = word_to_ix[outputs[i]]\n",
    "    # outputs X, y - (sample_size, seq_len), (sample_size) with value 0 < c < n_letters\n",
    "    return X, y\n",
    "\n",
    "test_text = file[:6]\n",
    "testX, testy = textToTensor(test_text, 1, 1)\n",
    "print(testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create one-hot encoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    \n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_one_hot_train_set(vectors):\n",
    "    _aux = torch.FloatTensor()\n",
    "    for i in range(vectors.size()[0]):\n",
    "        for j in vectors[i]:\n",
    "            _aux = torch.cat((_aux, torch.FloatTensor(one_hot_encode(np.array([[j]]),100))), 1)\n",
    "        #x_one_hot = _aux.view(vectors.size()[0],-1)\n",
    "    return _aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of text being one-hot-vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example string: First\n",
      "tensor([[ 46],\n",
      "        [ 67],\n",
      "        [ 81],\n",
      "        [ 82]])\n",
      "One hot representation: torch.Size([1, 4, 100]) \n",
      " tensor([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.],\n",
      "         [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "           0.]]])\n"
     ]
    }
   ],
   "source": [
    "test_text = file[:5]\n",
    "print(\"Example string: \"+str(test_text))\n",
    "testX, testy = textToTensor(test_text, 1, 1)\n",
    "print(testX)\n",
    "print(\"One hot representation: \"+str(get_one_hot_train_set(testX).size())+\" \\n \"+str(get_one_hot_train_set(testX)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "num_hidden = 100\n",
    "num_hidden_layers = 1\n",
    "learning_rate = 0.005\n",
    "\n",
    "sequence_length = 5\n",
    "step_size=1\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create iterator with minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text into indices\n",
    "idx_X, y = textToTensor(file[:20000], sequence_length, step_size)\n",
    "# one-hot-vectorize the train set\n",
    "X = get_one_hot_train_set(idx_X)\n",
    "X = X.view(idx_X.size()[0],-1)\n",
    "\n",
    "sample_size = len(y)\n",
    "train_size = int(0.9*sample_size)\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:], y[train_size:]\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=1, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=1, drop_last=True)\n",
    "\n",
    "print (len(X)/N)\n",
    "print(len(train_loader) + len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, sequence_length, num_hidden, num_output, num_hidden_layers, batch_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_output = num_output\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, num_hidden, num_hidden_layers, batch_first=True, nonlinearity=\"relu\")        \n",
    "        self.linear_out = nn.Linear(num_hidden, num_output)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = x.view(self.batch_size, self.sequence_length, self.input_size)\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        output = self.linear_out(output.view(-1, self.num_output))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.num_hidden_layers, self.batch_size, self.num_hidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(n_characters, sequence_length, num_hidden, n_characters, num_hidden_layers, batch_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] train loss: 6.779 val loss: 2.615 time: 0.704\n",
      "saving least val loss model from epoch [1]\n",
      "[2] train loss: 2.571 val loss: 2.508 time: 0.717\n",
      "saving least val loss model from epoch [2]\n",
      "[3] train loss: 2.496 val loss: 2.484 time: 0.787\n",
      "saving least val loss model from epoch [3]\n",
      "[4] train loss: 2.470 val loss: 2.476 time: 0.795\n",
      "saving least val loss model from epoch [4]\n",
      "[5] train loss: 2.457 val loss: 2.472 time: 0.821\n",
      "saving least val loss model from epoch [5]\n",
      "[6] train loss: 2.448 val loss: 2.463 time: 0.824\n",
      "saving least val loss model from epoch [6]\n",
      "[7] train loss: 2.440 val loss: 2.466 time: 0.815\n",
      "[8] train loss: 2.434 val loss: 2.462 time: 0.825\n",
      "saving least val loss model from epoch [8]\n",
      "[9] train loss: 2.428 val loss: 2.463 time: 0.808\n",
      "[10] train loss: 2.423 val loss: 2.460 time: 0.841\n",
      "saving least val loss model from epoch [10]\n",
      "[11] train loss: 2.418 val loss: 2.459 time: 0.816\n",
      "saving least val loss model from epoch [11]\n",
      "[12] train loss: 2.414 val loss: 2.462 time: 0.816\n",
      "[13] train loss: 2.410 val loss: 2.466 time: 0.805\n",
      "[14] train loss: 2.407 val loss: 2.466 time: 0.817\n",
      "[15] train loss: 2.402 val loss: 2.470 time: 0.820\n",
      "[16] train loss: 2.399 val loss: 2.470 time: 0.840\n",
      "[17] train loss: 2.396 val loss: 2.469 time: 0.796\n",
      "[18] train loss: 2.392 val loss: 2.474 time: 0.799\n",
      "[19] train loss: 2.389 val loss: 2.478 time: 0.784\n",
      "[20] train loss: 2.385 val loss: 2.486 time: 0.783\n",
      "[21] train loss: 2.382 val loss: 2.494 time: 0.822\n",
      "[22] train loss: 2.379 val loss: 2.503 time: 0.831\n",
      "[23] train loss: 2.378 val loss: 2.496 time: 0.804\n",
      "[24] train loss: 2.375 val loss: 2.499 time: 0.851\n",
      "[25] train loss: 2.375 val loss: 2.496 time: 0.789\n",
      "[26] train loss: 2.371 val loss: 2.502 time: 0.793\n",
      "[27] train loss: 2.370 val loss: 2.506 time: 0.801\n",
      "[28] train loss: 2.368 val loss: 2.509 time: 0.809\n",
      "[29] train loss: 2.365 val loss: 2.514 time: 0.802\n",
      "[30] train loss: 2.366 val loss: 2.525 time: 0.785\n",
      "[31] train loss: 2.364 val loss: 2.525 time: 0.788\n",
      "[32] train loss: 2.363 val loss: 2.515 time: 0.787\n",
      "[33] train loss: 2.363 val loss: 2.517 time: 0.820\n",
      "[34] train loss: 2.359 val loss: 2.531 time: 0.787\n",
      "[35] train loss: 2.358 val loss: 2.530 time: 0.792\n",
      "[36] train loss: 2.355 val loss: 2.528 time: 0.791\n",
      "[37] train loss: 2.357 val loss: 2.529 time: 0.795\n",
      "[38] train loss: 2.353 val loss: 2.521 time: 0.787\n",
      "[39] train loss: 2.355 val loss: 2.518 time: 0.786\n",
      "[40] train loss: 2.353 val loss: 2.517 time: 0.802\n",
      "[41] train loss: 2.353 val loss: 2.516 time: 0.782\n",
      "[42] train loss: 2.353 val loss: 2.514 time: 0.798\n",
      "[43] train loss: 2.350 val loss: 2.522 time: 0.804\n",
      "[44] train loss: 2.350 val loss: 2.513 time: 0.808\n",
      "[45] train loss: 2.350 val loss: 2.525 time: 0.804\n",
      "[46] train loss: 2.346 val loss: 2.526 time: 0.804\n",
      "[47] train loss: 2.345 val loss: 2.532 time: 0.800\n",
      "[48] train loss: 2.344 val loss: 2.528 time: 0.803\n",
      "[49] train loss: 2.342 val loss: 2.526 time: 0.816\n",
      "[50] train loss: 2.342 val loss: 2.535 time: 0.801\n",
      "[51] train loss: 2.340 val loss: 2.552 time: 0.800\n",
      "[52] train loss: 2.342 val loss: 2.544 time: 0.811\n",
      "[53] train loss: 2.339 val loss: 2.556 time: 0.805\n",
      "[54] train loss: 2.338 val loss: 2.546 time: 0.811\n",
      "[55] train loss: 2.334 val loss: 2.553 time: 0.807\n",
      "[56] train loss: 2.332 val loss: 2.552 time: 0.812\n",
      "[57] train loss: 2.332 val loss: 2.569 time: 0.828\n",
      "[58] train loss: 2.331 val loss: 2.569 time: 0.811\n",
      "[59] train loss: 2.331 val loss: 2.577 time: 0.808\n",
      "[60] train loss: 2.333 val loss: 2.562 time: 0.816\n",
      "[61] train loss: 2.330 val loss: 2.569 time: 0.811\n",
      "[62] train loss: 2.329 val loss: 2.563 time: 0.806\n",
      "[63] train loss: 2.326 val loss: 2.556 time: 0.811\n",
      "[64] train loss: 2.328 val loss: 2.565 time: 0.811\n",
      "[65] train loss: 2.327 val loss: 2.561 time: 0.815\n",
      "[66] train loss: 2.327 val loss: 2.567 time: 0.821\n",
      "[67] train loss: 2.327 val loss: 2.575 time: 0.826\n",
      "[68] train loss: 2.323 val loss: 2.565 time: 0.821\n",
      "[69] train loss: 2.322 val loss: 2.560 time: 0.910\n",
      "[70] train loss: 2.322 val loss: 2.566 time: 0.913\n",
      "[71] train loss: 2.321 val loss: 2.553 time: 0.920\n",
      "[72] train loss: 2.321 val loss: 2.562 time: 0.841\n",
      "[73] train loss: 2.318 val loss: 2.567 time: 0.833\n",
      "[74] train loss: 2.321 val loss: 2.560 time: 0.982\n",
      "[75] train loss: 2.318 val loss: 2.571 time: 0.952\n",
      "[76] train loss: 2.320 val loss: 2.572 time: 1.019\n",
      "[77] train loss: 2.316 val loss: 2.585 time: 0.985\n",
      "[78] train loss: 2.322 val loss: 2.558 time: 0.954\n",
      "[79] train loss: 2.318 val loss: 2.562 time: 0.915\n",
      "[80] train loss: 2.316 val loss: 2.591 time: 0.896\n",
      "[81] train loss: 2.317 val loss: 2.586 time: 0.874\n",
      "[82] train loss: 2.316 val loss: 2.573 time: 0.872\n",
      "[83] train loss: 2.316 val loss: 2.584 time: 0.875\n",
      "[84] train loss: 2.315 val loss: 2.560 time: 0.877\n",
      "[85] train loss: 2.315 val loss: 2.563 time: 0.895\n",
      "[86] train loss: 2.314 val loss: 2.570 time: 0.900\n",
      "[87] train loss: 2.315 val loss: 2.592 time: 0.950\n",
      "[88] train loss: 2.319 val loss: 2.569 time: 0.894\n",
      "[89] train loss: 2.316 val loss: 2.570 time: 0.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-759:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/hveiga/Desktop/Data_Science/dl-venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-271-956ee0aa86b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "plot_train, plot_val = [], []\n",
    "best_val_loss = 100.0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    val_loss, val_acc = 0.0, 0.0\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    # train\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # forward, backward, optimize\n",
    "        hidden = hidden.detach()\n",
    "        optimizer.zero_grad()        \n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "\n",
    "\n",
    "    # evaluate with validation set\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            # forward only\n",
    "            hidden = hidden.detach()\n",
    "            output, hidden = model(data, hidden)\n",
    "            loss = loss_func(output, target)\n",
    "\n",
    "            val_loss += loss.item()/len(val_loader)\n",
    "\n",
    "    plot_train.append(train_loss)\n",
    "    plot_val.append(val_loss)\n",
    "\n",
    "    print('[%d] train loss: %.3f val loss: %.3f time: %.3f' % (epoch + 1, train_loss, val_loss, time.time() - start_time))\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_loss_weight')\n",
    "        print('saving least val loss model from epoch [%d]'% (epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. <br>\n",
    "To start the generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = model.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = model(prime_input[p].view(1, batch_size, -1), hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model(inp.view(1, batch_size, -1), hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
